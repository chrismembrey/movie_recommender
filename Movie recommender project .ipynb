{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project uses the movielens dataset which can be found in the folder this notebook is contained in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Movie Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-30bf0b4413ec>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  moviedata['title'] = moviedata.title.str.replace('(\\(\\d\\d\\d\\d\\))','')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>97</td>\n",
       "      <td>Hate (Haine, La)</td>\n",
       "      <td>Crime|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>98</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>Action|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>99</td>\n",
       "      <td>Heidi Fleiss: Hollywood Madam</td>\n",
       "      <td>Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>100</td>\n",
       "      <td>City Hall</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>101</td>\n",
       "      <td>Bottle Rocket</td>\n",
       "      <td>Adventure|Comedy|Crime|Romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    movieId                          title  \\\n",
       "0         1                      Toy Story   \n",
       "1         2                        Jumanji   \n",
       "2         3               Grumpier Old Men   \n",
       "3         4              Waiting to Exhale   \n",
       "4         5    Father of the Bride Part II   \n",
       "..      ...                            ...   \n",
       "95       97               Hate (Haine, La)   \n",
       "96       98                       Shopping   \n",
       "97       99  Heidi Fleiss: Hollywood Madam   \n",
       "98      100                      City Hall   \n",
       "99      101                  Bottle Rocket   \n",
       "\n",
       "                                         genres  \n",
       "0   Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                    Adventure|Children|Fantasy  \n",
       "2                                Comedy|Romance  \n",
       "3                          Comedy|Drama|Romance  \n",
       "4                                        Comedy  \n",
       "..                                          ...  \n",
       "95                                  Crime|Drama  \n",
       "96                              Action|Thriller  \n",
       "97                                  Documentary  \n",
       "98                               Drama|Thriller  \n",
       "99               Adventure|Comedy|Crime|Romance  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviedata = pd.read_csv('file:///Volumes/WORK/Data%20Science/practice%20data%20sets/Movies/movies.csv')\n",
    "moviedata['Year'] = moviedata.title.str.extract('(\\(\\d\\d\\d\\d\\))', expand = False)\n",
    "moviedata['Year'] = moviedata.Year.str.extract('(\\d\\d\\d\\d)', expand = False)\n",
    "\n",
    "moviedata['title'] = moviedata.title.str.replace('(\\(\\d\\d\\d\\d\\))','')\n",
    "moviedata['title'] = [x.strip() for x in moviedata.title]\n",
    "moviedata = moviedata.drop('Year', axis = 1)\n",
    "\n",
    "moviedata.head(100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find ratings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>169</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2471</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48516</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2571</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>109487</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       1      169     2.5\n",
       "1       1     2471     3.0\n",
       "2       1    48516     5.0\n",
       "3       2     2571     3.5\n",
       "4       2   109487     4.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingsdata = pd.read_csv('file:///Volumes/WORK/Data%20Science/practice%20data%20sets/movies/ratings.csv')\n",
    "\n",
    "ratingsdata = ratingsdata.drop('timestamp', axis = 1)\n",
    "\n",
    "ratingsdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def recommender_simple(movies , ratings):\n",
    "    '''A very simple recommendation system that works in a collaberative filtering manner\n",
    "    \n",
    "    instead of finding the correlation between users like you normally would, \n",
    "    the similarity here is just the user ratings - your rating.\n",
    "    The closer to zero between your rating group and the user rating group, the greater the similarity'''\n",
    "    \n",
    "    input_movies = pd.DataFrame({'title': movies , 'rating': ratings})\n",
    "    input_id = moviedata[moviedata['title'].isin(input_movies['title'].to_list())]\n",
    "\n",
    "    input_movies = pd.merge(input_id, input_movies)\n",
    "    input_movies = input_movies.drop('genres', axis = 1)\n",
    "\n",
    "    user_ratings_for_movies = ratingsdata[ratingsdata['movieId'].isin(input_movies['movieId'].to_list())]\n",
    "\n",
    "    grouped_users = user_ratings_for_movies.groupby(['userId'])\n",
    "    #sort users by how many of the films they have rated matches the number of films you \n",
    "    grouped_users = sorted(grouped_users, key = lambda x: len(x[1]), reverse = True)\n",
    "    grouped_users = grouped_users[0:100]\n",
    "\n",
    "    similarity_for_users = {}\n",
    "\n",
    "    for name, group in grouped_users:\n",
    "        group = group.sort_values(by = 'movieId').reset_index()\n",
    "        input_movies = input_movies.sort_values(by = 'movieId')\n",
    "        \n",
    "        \n",
    "        summ = 0\n",
    "        for user,you in zip(input_movies.merge(group, on = 'movieId', how = 'right')['rating_y'],input_movies.merge(group, on = 'movieId', how = 'right')['rating_x']):\n",
    "            summ += ((user - you)/2)**2\n",
    "            \n",
    "        \n",
    "        \n",
    "        similarity_for_users[name] = summ\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    similarity_for_users = pd.DataFrame({'user_id': similarity_for_users.keys() , 'similarity': similarity_for_users.values()})\\\n",
    "\n",
    "    similarity_for_users['absolute'] = similarity_for_users.similarity.apply(lambda x: abs(x))\n",
    "\n",
    "    similarity_for_users = similarity_for_users.sort_values(by = 'absolute')\n",
    "    \n",
    "    \n",
    "    films_to_recommend = ratingsdata[(ratingsdata.userId == similarity_for_users.iloc[0,0]) & (ratingsdata['movieId'].isin(input_movies['movieId'].to_list()) == False)]\\\n",
    "    .sort_values(by = 'rating', ascending = False)[:10]\n",
    "    \n",
    "    for number, x in enumerate(moviedata[moviedata['movieId'].isin(films_to_recommend['movieId'].to_list())].title):\n",
    "        print(f'Recommendation {number+1}: '+ x.upper())\n",
    "        time.sleep(2)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for films you like that may be contained in the dataset so that you may use them in the recomendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_films(film_search):\n",
    "    list1 = list(moviedata.title.unique())\n",
    "    return [x for x in list1 if film_search in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star Wars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Star Wars: Episode IV - A New Hope',\n",
       " 'Star Wars: Episode V - The Empire Strikes Back',\n",
       " 'Star Wars: Episode VI - Return of the Jedi',\n",
       " 'Star Wars: Episode I - The Phantom Menace',\n",
       " 'Star Wars: Episode II - Attack of the Clones',\n",
       " 'Star Wars: Episode III - Revenge of the Sith',\n",
       " 'Star Wars: The Clone Wars',\n",
       " \"Empire of Dreams: The Story of the 'Star Wars' Trilogy\",\n",
       " \"Star Wars Uncut: Director's Cut\",\n",
       " 'Star Wars: Threads of Destiny',\n",
       " 'Star Wars: Episode VII - The Force Awakens',\n",
       " 'The Star Wars Holiday Special',\n",
       " 'Robot Chicken: Star Wars',\n",
       " 'Plastic Galaxy: The Story of Star Wars Toys']"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_films(film_search = input())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list the films you like/dont like to watch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "films_i_have_watched = ['Star Wars: Episode IV - A New Hope',\n",
    " 'Star Wars: Episode V - The Empire Strikes Back',\n",
    " 'Star Wars: Episode VI - Return of the Jedi',\n",
    " 'Star Wars: Episode I - The Phantom Menace',\n",
    " 'Star Wars: Episode II - Attack of the Clones',\n",
    " 'Star Wars: Episode III - Revenge of the Sith',\n",
    " 'Star Wars: The Clone Wars',\n",
    " \"Empire of Dreams: The Story of the 'Star Wars' Trilogy\",\n",
    " \"Star Wars Uncut: Director's Cut\",\n",
    " 'Star Wars: Threads of Destiny',\n",
    " 'Star Wars: Episode VII - The Force Awakens']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rate them in the order you gave above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what_i_rate_them = np.random.randint(5,6,len(films_i_have_watched)) #here i have given random ratings for testing\n",
    "what_i_rate_them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "what_i_rate_them = [5,4,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plug it all into the recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation 1: DAY AFTER TOMORROW, THE\n",
      "Recommendation 2: HARRY POTTER AND THE PRISONER OF AZKABAN\n",
      "Recommendation 3: SPIDER-MAN 2\n",
      "Recommendation 4: HAROLD AND KUMAR GO TO WHITE CASTLE\n",
      "Recommendation 5: CASINO ROYALE\n",
      "Recommendation 6: AVENGERS, THE\n",
      "Recommendation 7: IN TIME\n",
      "Recommendation 8: TWILIGHT SAGA: BREAKING DAWN - PART 1, THE\n",
      "Recommendation 9: DARK KNIGHT RISES, THE\n",
      "Recommendation 10: SHERLOCK HOLMES: A GAME OF SHADOWS\n"
     ]
    }
   ],
   "source": [
    "recommender_simple(films_i_have_watched , what_i_rate_them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Recommender Using Scikit Surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the recommender ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB - to go straight to the function in order to see your recommendations, head to the bottom of the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find films to rate from the database like before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_films(film_search):\n",
    "    list1 = list(moviedata.title.unique())\n",
    "    return [x for x in list1 if film_search in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star Wars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Star Wars: Episode IV - A New Hope',\n",
       " 'Star Wars: Episode V - The Empire Strikes Back',\n",
       " 'Star Wars: Episode VI - Return of the Jedi',\n",
       " 'Star Wars: Episode I - The Phantom Menace',\n",
       " 'Star Wars: Episode II - Attack of the Clones',\n",
       " 'Star Wars: Episode III - Revenge of the Sith',\n",
       " 'Star Wars: The Clone Wars',\n",
       " \"Empire of Dreams: The Story of the 'Star Wars' Trilogy\",\n",
       " \"Star Wars Uncut: Director's Cut\",\n",
       " 'Star Wars: Threads of Destiny',\n",
       " 'Star Wars: Episode VII - The Force Awakens',\n",
       " 'The Star Wars Holiday Special',\n",
       " 'Robot Chicken: Star Wars',\n",
       " 'Plastic Galaxy: The Story of Star Wars Toys']"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_films(film_search = input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "films_i_have_watched = ['Star Wars: Episode IV - A New Hope',\n",
    " 'Star Wars: Episode V - The Empire Strikes Back',\n",
    " 'Star Wars: Episode VI - Return of the Jedi',\n",
    " 'Star Wars: Episode I - The Phantom Menace',\n",
    " 'Star Wars: Episode II - Attack of the Clones',\n",
    " 'Star Wars: Episode III - Revenge of the Sith',\n",
    " 'Star Wars: The Clone Wars',\n",
    " \"Empire of Dreams: The Story of the 'Star Wars' Trilogy\",\n",
    " \"Star Wars Uncut: Director's Cut\",\n",
    " 'Star Wars: Threads of Destiny',\n",
    " 'Star Wars: Episode VII - The Force Awakens']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rate them in the order you gave above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what_i_rate_them = np.random.randint(5,6,len(films_i_have_watched)) #here i have given random ratings for testing\n",
    "what_i_rate_them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "what_i_rate_them = [5,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>169</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2471</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48516</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2571</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>109487</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       1      169     2.5\n",
       "1       1     2471     3.0\n",
       "2       1    48516     5.0\n",
       "3       2     2571     3.5\n",
       "4       2   109487     4.0"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = ratingsdata.copy()\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w_your_ratings = pd.concat([dataset,pd.DataFrame(np.array([[*['you' for x in range(len(what_i_rate_them))]],\n",
    "                       [*films_i_have_watched], [*what_i_rate_them]]).T, columns = ['userId','movieId','rating'])] , axis = 0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w_your_ratings.drop('index', inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install scikit surprise\n",
    "\n",
    "# !pip install scikit-surprise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import surprise as sur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = sur.Reader(rating_scale = (0,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = sur.Dataset.load_from_df(data_w_your_ratings[['userId', 'movieId', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross validation, train test split and grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "raw_ratings = data1.raw_ratings\n",
    "random.seed(3)\n",
    "\n",
    "random.shuffle(raw_ratings)\n",
    "\n",
    "\n",
    "threshold = (int(.9 * len(raw_ratings)))\n",
    "\n",
    "A_raw_ratings = raw_ratings[:threshold]\n",
    "B_raw_ratings = raw_ratings[threshold:] #making test set\n",
    "\n",
    "data1.raw_ratings = A_raw_ratings #this is now the train set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instatiate the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid search...\n"
     ]
    }
   ],
   "source": [
    "print('grid search...')\n",
    "\n",
    "\n",
    "param_grid = {'n_epochs': [5,10], 'lr_all':[0.002, 0.005]}\n",
    "\n",
    "grid_search = sur.model_selection.GridSearchCV(sur.SVD,\n",
    "                                              param_grid,\n",
    "                                              measures = ['rmse'],\n",
    "                                              cv = 3,\n",
    "                                              refit = True)\n",
    "\n",
    "grid_search.fit(data1)\n",
    "\n",
    "algo = grid_search.best_estimator['rmse']\n",
    "\n",
    "\n",
    "\n",
    "trainset = data1.build_full_trainset()\n",
    "algo.fit(trainset)\n",
    "\n",
    "#training acuracy\n",
    "trainset_build = trainset.build_testset()\n",
    "predictions_train = algo.test(trainset_build)\n",
    "\n",
    "print('Training Score: ', sur.accuracy.rmse(predictions_train))\n",
    "\n",
    "\n",
    "\n",
    "#testing accuracy\n",
    "testset = data1.construct_testset(B_raw_ratings)\n",
    "predictions_tets = algo.test(testset)\n",
    "\n",
    "print('Test Score (rated items): ', sur.accuracy.rmse(predictions_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#testing on movies that users havnt seen\n",
    "no_ratings = trainset.build_anti_testset()\n",
    "predictions_no_ratings = algo.test(no_ratings)\n",
    "\n",
    "print('Test score (unseen items): ', sur.accuracy.rmse(predictions_no_ratings, verbose = False))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the recomendation with the predicted ratings for eah user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = []\n",
    "items = []\n",
    "average = []\n",
    "prediction = []\n",
    "\n",
    "for x in predictions_no_ratings:\n",
    "    \n",
    "    users.append(x.uid)\n",
    "    items.append(x.iid)\n",
    "    average.append(x.r_ui)\n",
    "    prediction.append(x.est)\n",
    "    \n",
    "pred_df = pd.DataFrame({'users': users ,\n",
    "                       'items': items,\n",
    "                       'average': average,\n",
    "                       'prediction' : prediction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recomendations = defaultdict()\n",
    "for user , items in pred_df.groupby('users')[['items' , 'prediction']]:\n",
    "    items = items.sort_values(by = 'prediction', ascending = False).head(10)\n",
    "    recomendations[user] = [(x[0] , x[1]) for x in zip(items['items'] , items['prediction'])]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for number, x in enumerate(recomendations['you']):\n",
    "    print(f'Recommendion {number}: ', moviedata.title[list(moviedata.movieId).index(x)].upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for ML Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_films(film_search):\n",
    "    list1 = list(moviedata.title.unique())\n",
    "    return [x for x in list1 if film_search in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star Wars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Star Wars: Episode IV - A New Hope',\n",
       " 'Star Wars: Episode V - The Empire Strikes Back',\n",
       " 'Star Wars: Episode VI - Return of the Jedi',\n",
       " 'Star Wars: Episode I - The Phantom Menace',\n",
       " 'Star Wars: Episode II - Attack of the Clones',\n",
       " 'Star Wars: Episode III - Revenge of the Sith',\n",
       " 'Star Wars: The Clone Wars',\n",
       " \"Empire of Dreams: The Story of the 'Star Wars' Trilogy\",\n",
       " \"Star Wars Uncut: Director's Cut\",\n",
       " 'Star Wars: Threads of Destiny',\n",
       " 'Star Wars: Episode VII - The Force Awakens',\n",
       " 'The Star Wars Holiday Special',\n",
       " 'Robot Chicken: Star Wars',\n",
       " 'Plastic Galaxy: The Story of Star Wars Toys']"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_films(film_search = input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "films_i_have_watched = ['Star Wars: Episode IV - A New Hope',\n",
    " 'Star Wars: Episode V - The Empire Strikes Back',\n",
    " 'Star Wars: Episode VI - Return of the Jedi',\n",
    " 'Star Wars: Episode I - The Phantom Menace',\n",
    " 'Star Wars: Episode II - Attack of the Clones',\n",
    " 'Star Wars: Episode III - Revenge of the Sith',\n",
    " 'Star Wars: The Clone Wars',\n",
    " \"Empire of Dreams: The Story of the 'Star Wars' Trilogy\",\n",
    " \"Star Wars Uncut: Director's Cut\",\n",
    " 'Star Wars: Threads of Destiny',\n",
    " 'Star Wars: Episode VII - The Force Awakens']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what_i_rate_them = np.random.randint(5,6,len(films_i_have_watched)) #here i have given random ratings for testing\n",
    "what_i_rate_them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "what_i_rate_them = [5,4,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function that uses a singular value decomposition algorith trained on the data above**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_recommend(movies , ratings):\n",
    "    dataset = ratingsdata.copy()\n",
    "    \n",
    "    \n",
    "    data_w_your_ratings = pd.concat([dataset,pd.DataFrame(np.array([[*['you' for x in range(len(what_i_rate_them))]],\n",
    "                       [*films_i_have_watched], [*what_i_rate_them]]).T, columns = ['userId','movieId','rating'])] , axis = 0).reset_index()\n",
    "    data_w_your_ratings.drop('index', inplace = True, axis = 1)\n",
    "    \n",
    "    \n",
    "    data1 = sur.Dataset.load_from_df(data_w_your_ratings[['userId', 'movieId', 'rating']], sur.Reader(rating_scale = (0,5)))\n",
    "    \n",
    "    \n",
    "    random.seed(3)\n",
    "\n",
    "    random.shuffle(data1.raw_ratings)\n",
    "    \n",
    "    #train test split\n",
    "    threshold = (int(.9 * len(raw_ratings)))\n",
    "\n",
    "    A_raw_ratings = raw_ratings[:threshold]\n",
    "    B_raw_ratings = raw_ratings[threshold:] #making test set\n",
    "\n",
    "    data1.raw_ratings = A_raw_ratings #this is now the train set\n",
    "    \n",
    "    #algorithm\n",
    "    algo = grid_search.best_estimator['rmse']\n",
    "    trainset = data1.build_full_trainset()\n",
    "    algo.fit(trainset)\n",
    "    \n",
    "    #testing on movies that users havnt seen\n",
    "    no_ratings = trainset.build_anti_testset()\n",
    "    predictions_no_ratings = algo.test(no_ratings)\n",
    "\n",
    "    \n",
    "    users = []\n",
    "    items = []\n",
    "    average = []\n",
    "    prediction = []\n",
    "\n",
    "    for x in predictions_no_ratings:\n",
    "\n",
    "        users.append(x.uid)\n",
    "        items.append(x.iid)\n",
    "        average.append(x.r_ui)\n",
    "        prediction.append(x.est)\n",
    "\n",
    "    pred_df = pd.DataFrame({'users': users ,\n",
    "                           'items': items,\n",
    "                           'average': average,\n",
    "                           'prediction' : prediction})\n",
    "\n",
    "    recomendations = defaultdict()\n",
    "    for user , items in pred_df.groupby('users')[['items' , 'prediction']]:\n",
    "        items = items.sort_values(by = 'prediction', ascending = False).head(10)\n",
    "        recomendations[user] = [(x[0] , x[1]) for x in zip(items['items'] , items['prediction'])]\n",
    "\n",
    "\n",
    "    for number, x in enumerate(recomendations['you']):\n",
    "        print(f'Recommendion {number}: ', moviedata.title[list(moviedata.movieId).index(x)].upper())\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def collaberative_recommender(movies , ratings):\n",
    "#     input_movies = pd.DataFrame({'title': movies , 'rating': ratings})\n",
    "#     input_id = moviedata[moviedata['title'].isin(input_movies['title'].to_list())]\n",
    "    \n",
    "#     input_movies = pd.merge(input_id, input_movies)\n",
    "#     input_movies = input_movies.drop('genres', axis = 1)\n",
    "    \n",
    "#     user_ratings_for_movies = ratingsdata[ratingsdata['movieId'].isin(input_movies['movieId'].to_list())]\n",
    "    \n",
    "#     grouped_users = user_ratings_for_movies.groupby(['userId'])\n",
    "#     grouped_users = sorted(grouped_users, key = lambda x: len(x[1]), reverse = True)\n",
    "#     grouped_users = grouped_users[0:100]\n",
    "    \n",
    "#     pearsoncorrelation_for_users = {}\n",
    "    \n",
    "#     for name, group in grouped_users:\n",
    "#         group = group.sort_values(by = 'movieId')\n",
    "#         input_movies = input_movies.sort_values(by = 'movieId')\n",
    "#         nratings = len(group)\n",
    "        \n",
    "    \n",
    "#         our_usergroup_df_for_y_correl = input_movies[input_movies['movieId'].isin(group['movieId'])]\n",
    "#         our_usergroupratings_for_y_correl = our_usergroup_df_for_y_correl['rating'].to_list()\n",
    "        \n",
    "#         previoususerratings_for_x_correl = group['rating'].to_list()\n",
    "        \n",
    "#         Sxx = sum([i**2 for i in previoususerratings_for_x_correl]) - pow(sum(previoususerratings_for_x_correl),2)/float(nratings)\n",
    "#         Syy = sum([i**2 for i in our_usergroupratings_for_y_correl]) - pow(sum(our_usergroupratings_for_y_correl),2)/float(nratings)\n",
    "#         Sxy = sum([a*b for a,b in zip(previoususerratings_for_x_correl,our_usergroupratings_for_y_correl)]) - sum(previoususerratings_for_x_correl) * sum(our_usergroupratings_for_y_correl)/nratings\n",
    "        \n",
    "#         if Sxx == 0 or Syy == 0:\n",
    "#             pearsoncorrelation_for_users[name] = 0\n",
    "#         else:\n",
    "#             pearsoncorrelation_for_users[name] = Sxy/sqrt(Sxx*Syy)\n",
    "\n",
    "#     pearsondf = pd.DataFrame.from_dict(pearsoncorrelation_for_users , orient = 'index')\n",
    "#     pearsondf.columns = ['Similarity Index']\n",
    "#     pearsondf['userId'] = pearsondf.index\n",
    "#     pearsondf.index = range(len(pearsondf))\n",
    "    \n",
    "#     topusers = pearsondf.sort_values(by = 'Similarity Index', ascending = False)\n",
    "#     topusers_30 = topusers[0:30]\n",
    "#     topusers_30_ratings = topusers_30.merge(ratingsdata, left_on = 'userId', right_on = 'userId', how = 'inner')\n",
    "#     topusers_30_ratings['weighted rating'] = topusers_30_ratings['rating']*topusers_30_ratings['Similarity Index']\n",
    "#     topusers_30_ratings.head()\n",
    "    \n",
    "#     weighted_rating_sum_of_each_movie = topusers_30_ratings.groupby('movieId').sum()[['Similarity Index', 'weighted rating']]\n",
    "#     weighted_rating_sum_of_each_movie.columns = ['Similarity Index Total', 'sum weighted rating']\n",
    "#     weighted_rating_sum_of_each_movie['Movie Score'] = weighted_rating_sum_of_each_movie['sum weighted rating']/weighted_rating_sum_of_each_movie['Similarity Index Total']\n",
    "#     weighted_rating_sum_of_each_movie['movieId'] =  weighted_rating_sum_of_each_movie.index\n",
    "#     weighted_rating_sum_of_each_movie =  weighted_rating_sum_of_each_movie.sort_values(by = 'Movie Score', ascending = False)\n",
    "\n",
    "#     movies_to_recommend = weighted_rating_sum_of_each_movie[:5]\n",
    "#     movies_to_recommend = moviedata[moviedata['movieId'].isin(movies_to_recommend['movieId'])]\n",
    "#     movies_to_recommend.index = range(1,len(movies_to_recommend.title)+1)\n",
    "#     movies_to_recommend = movies_to_recommend.title.to_frame()\n",
    "    \n",
    "#     return movies_to_recommend\n",
    "\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
